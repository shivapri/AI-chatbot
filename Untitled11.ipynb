{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZk6CmyT81V_"
   },
   "source": [
    "# IMPORTING ALL LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk  #The Natural Language Toolkit (NLTK) is an open source Python library\n",
    "              #for Natural Language Processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UYsn9wBQ9EGe"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AkdtkdZi9M2N"
   },
   "outputs": [],
   "source": [
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MF_Rg4qU9PLp"
   },
   "outputs": [],
   "source": [
    "import numpy #for arrays and other mathematical operations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "TtUsXhtXDqFh",
    "outputId": "0edc3742-7433-4bd6-a1bd-21ec2529276d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling tensorflow-2.3.0:\n",
      "  Would remove:\n",
      "    /usr/local/bin/estimator_ckpt_converter\n",
      "    /usr/local/bin/saved_model_cli\n",
      "    /usr/local/bin/tensorboard\n",
      "    /usr/local/bin/tf_upgrade_v2\n",
      "    /usr/local/bin/tflite_convert\n",
      "    /usr/local/bin/toco\n",
      "    /usr/local/bin/toco_from_protos\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.3.0.dist-info/*\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
      "Proceed (y/n)? y\n",
      "  Successfully uninstalled tensorflow-2.3.0\n"
     ]
    }
   ],
   "source": [
    "pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "id": "9Nq3R7CADqbn",
    "outputId": "c9b1872d-bc61-413b-d16d-c332ef3617ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.13.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/d3/651f95288a6cd9094f7411cdd90ef12a3d01a268009e0e3cd66b5c8d65bd/tensorflow-1.13.2-cp36-cp36m-manylinux1_x86_64.whl (92.6MB)\n",
      "\u001b[K     |████████████████████████████████| 92.6MB 45kB/s \n",
      "\u001b[?25hCollecting keras-applications>=1.0.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.35.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.32.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (3.12.4)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.3.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.1.0)\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
      "\u001b[K     |████████████████████████████████| 368kB 33.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.8.1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.10.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.18.5)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.1.2)\n",
      "Collecting tensorboard<1.14.0,>=1.13.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 36.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.2) (2.10.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.2) (50.3.0)\n",
      "Collecting mock>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.2.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.2.0)\n",
      "Installing collected packages: keras-applications, mock, tensorflow-estimator, tensorboard, tensorflow\n",
      "  Found existing installation: tensorflow-estimator 2.3.0\n",
      "    Uninstalling tensorflow-estimator-2.3.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
      "  Found existing installation: tensorboard 2.3.0\n",
      "    Uninstalling tensorboard-2.3.0:\n",
      "      Successfully uninstalled tensorboard-2.3.0\n",
      "Successfully installed keras-applications-1.0.8 mock-4.0.2 tensorboard-1.13.1 tensorflow-1.13.2 tensorflow-estimator-1.13.0\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==1.13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "42XN0evZ9fEi",
    "outputId": "f64e7218-4d3f-45c4-bacf-929e242d10b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tflearn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/ec/e9ce1b52e71f6dff3bd944f020cef7140779e783ab27512ea7c7275ddee5/tflearn-0.3.2.tar.gz (98kB)\n",
      "\r",
      "\u001b[K     |███▎                            | 10kB 19.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 20kB 1.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 30kB 2.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 40kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 51kB 2.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 61kB 2.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 71kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 81kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 92kB 2.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 102kB 2.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.18.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.15.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (7.0.0)\n",
      "Building wheels for collected packages: tflearn\n",
      "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for tflearn: filename=tflearn-0.3.2-cp36-none-any.whl size=128207 sha256=20ae12fd577cd39aeaac70d33ea0d7199088469618148915935b56ad6b1e5a01\n",
      "  Stored in directory: /root/.cache/pip/wheels/d0/f6/69/0ef3ee395aac2e5d15d89efd29a9a216f3c27767b43b72c006\n",
      "Successfully built tflearn\n",
      "Installing collected packages: tflearn\n",
      "Successfully installed tflearn-0.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "GZ1DSnfT9hhV",
    "outputId": "b87cfda0-d5d0-4887-f4b2-51f15b06c3a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import tflearn  #important for creating model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "z3NqVFgr9_c3"
   },
   "outputs": [],
   "source": [
    "import tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lP1kKciX-I11"
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qHLbMcy_-gpl"
   },
   "outputs": [],
   "source": [
    "import json #because we are using json datasset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gZcJ_ZjrEawc"
   },
   "outputs": [],
   "source": [
    "with open(\"intents.json\") as file:\n",
    "  data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "id": "rskZBrR8FHpL",
    "outputId": "dd027b88-69d2-4d5c-e478-5ec6092c685e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tag': 'greeting', 'patterns': ['Hi', 'How are you', 'Is anyone there?', 'Hello', 'Good day', 'Whats up'], 'responses': ['Hello!', 'Good to see you again!', 'Hi there, how can I help?'], 'context_set': ''}, {'tag': 'goodbye', 'patterns': ['cya', 'See you later', 'Goodbye', 'I am Leaving', 'Have a Good day'], 'responses': ['Sad to see you go :(', 'Talk to you later', 'Goodbye!'], 'context_set': ''}, {'tag': 'age', 'patterns': ['how old', 'how old is shivam', 'what is your age', 'how old are you', 'age?'], 'responses': ['I am 21 years old!', '21 years young!'], 'context_set': ''}, {'tag': 'name', 'patterns': ['what is your name', 'what should I call you', 'whats your name?'], 'responses': ['You can call me Tim.', \"I'm Tim!\", \"I'm Tim aka Tech With Tim.\"], 'context_set': ''}, {'tag': 'shop', 'patterns': ['Id like to buy something', 'whats on the menu', 'what do you reccommend?', 'could i get something to eat'], 'responses': ['We sell chocolate chip cookies for $2!', 'Cookies are on the menu!'], 'context_set': ''}, {'tag': 'hours', 'patterns': ['when are you guys open', 'what are your hours', 'hours of operation'], 'responses': ['We are open 7am-4pm Monday-Friday!'], 'context_set': ''}, {'tag': 'hobbies', 'patterns': ['which music should i listen', 'what is the most interesting band', 'what is favorite genre of music'], 'responses': ['AC/DC rock band', 'singing Metallica', 'Ghoultown', 'Pantera heavy metal'], 'context_set': ''}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\"], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}, {'tag': 'mopeds', 'patterns': ['Which mopeds do you have?', 'What kinds of mopeds are there?', 'What do you rent?'], 'responses': ['We rent Yamaha, Piaggio and Vespa mopeds', 'We have Piaggio, Vespa and Yamaha mopeds']}, {'tag': 'payments', 'patterns': ['Do you take credit cards?', 'Do you accept Mastercard?', 'Are you cash only?'], 'responses': ['We accept VISA, Mastercard and AMEX', 'We accept most major credit cards']}, {'tag': 'opentoday', 'patterns': ['Are you open today?', 'When do you open today?', 'What are your hours today?'], 'responses': [\"We're open every day from 9am-9pm\", 'Our hours are 9am-9pm every day']}, {'tag': 'rental', 'patterns': ['Can we rent a moped?', \"I'd like to rent a moped\", 'How does this work?'], 'responses': ['Are you looking to rent today or later this week?'], 'context_set': 'rentalday'}, {'tag': 'today', 'patterns': ['today'], 'responses': ['For rentals today please call 1-800-MYMOPED', 'Same-day rentals please call 1-800-MYMOPED'], 'context_filter': 'rentalday'}]\n"
     ]
    }
   ],
   "source": [
    "print(data[\"intents\"]) #the intention of our chat is saved at the intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-8OeadKAFLtj"
   },
   "outputs": [],
   "source": [
    "words=[]\n",
    "labels = []\n",
    "docs_x = []\n",
    "docs_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt') #for using tokenizer we have to download punkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uVba4RPlF8ws"
   },
   "outputs": [],
   "source": [
    "for intent in data[\"intents\"]:\n",
    "  for pattern in intent[\"patterns\"]:\n",
    "    wrds = nltk.word_tokenize(pattern)   #for splitting the pattern of words in sentence of chat\n",
    "    words.extend(wrds)  #these list of words are added to another empty list words\n",
    "    docs_x.append(wrds) #words added to docs_x\n",
    "    docs_y.append(intent[\"tag\"]) #corresponding tags added to docs_y\n",
    "  if intent[\"tag\"] not in labels: \n",
    "    labels.append(intent[\"tag\"]) #adding the tags to labels list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "45BouCkDZt-H",
    "outputId": "53140f6b-58fa-44c0-bac1-f09f1372f905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 859
    },
    "id": "JOFZiV0GfRqa",
    "outputId": "17ee31d7-d9cc-4168-ed45-3952d15c7359"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hi'],\n",
       " ['How', 'are', 'you'],\n",
       " ['Is', 'anyone', 'there', '?'],\n",
       " ['Hello'],\n",
       " ['Good', 'day'],\n",
       " ['Whats', 'up'],\n",
       " ['cya'],\n",
       " ['See', 'you', 'later'],\n",
       " ['Goodbye'],\n",
       " ['I', 'am', 'Leaving'],\n",
       " ['Have', 'a', 'Good', 'day'],\n",
       " ['how', 'old'],\n",
       " ['how', 'old', 'is', 'shivam'],\n",
       " ['what', 'is', 'your', 'age'],\n",
       " ['how', 'old', 'are', 'you'],\n",
       " ['age', '?'],\n",
       " ['what', 'is', 'your', 'name'],\n",
       " ['what', 'should', 'I', 'call', 'you'],\n",
       " ['whats', 'your', 'name', '?'],\n",
       " ['Id', 'like', 'to', 'buy', 'something'],\n",
       " ['whats', 'on', 'the', 'menu'],\n",
       " ['what', 'do', 'you', 'reccommend', '?'],\n",
       " ['could', 'i', 'get', 'something', 'to', 'eat'],\n",
       " ['when', 'are', 'you', 'guys', 'open'],\n",
       " ['what', 'are', 'your', 'hours'],\n",
       " ['hours', 'of', 'operation'],\n",
       " ['which', 'music', 'should', 'i', 'listen'],\n",
       " ['what', 'is', 'the', 'most', 'interesting', 'band'],\n",
       " ['what', 'is', 'favorite', 'genre', 'of', 'music'],\n",
       " ['Thanks'],\n",
       " ['Thank', 'you'],\n",
       " ['That', \"'s\", 'helpful'],\n",
       " ['Which', 'mopeds', 'do', 'you', 'have', '?'],\n",
       " ['What', 'kinds', 'of', 'mopeds', 'are', 'there', '?'],\n",
       " ['What', 'do', 'you', 'rent', '?'],\n",
       " ['Do', 'you', 'take', 'credit', 'cards', '?'],\n",
       " ['Do', 'you', 'accept', 'Mastercard', '?'],\n",
       " ['Are', 'you', 'cash', 'only', '?'],\n",
       " ['Are', 'you', 'open', 'today', '?'],\n",
       " ['When', 'do', 'you', 'open', 'today', '?'],\n",
       " ['What', 'are', 'your', 'hours', 'today', '?'],\n",
       " ['Can', 'we', 'rent', 'a', 'moped', '?'],\n",
       " ['I', \"'d\", 'like', 'to', 'rent', 'a', 'moped'],\n",
       " ['How', 'does', 'this', 'work', '?'],\n",
       " ['today']]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "id": "VyWADIdofZ2M",
    "outputId": "3f65a335-0e3d-4965-983f-635273b41dcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['greeting', 'goodbye', 'age', 'name', 'shop', 'hours', 'hobbies', 'thanks', 'mopeds', 'payments', 'opentoday', 'rental', 'today']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "-aTVaAVhfxIK"
   },
   "outputs": [],
   "source": [
    "words = [stemmer.stem(w.lower()) for w in words if w not in \"?\"]\n",
    "words = sorted(list(set(words)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "id": "sEtZMqTzKR1v",
    "outputId": "43e74204-1605-4f75-a995-c7658d9decd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'d\", \"'s\", 'a', 'acceiv', 'ag', 'am', 'anyon', 'ar', 'band', 'buy', 'cal', 'can', 'card', 'cash', 'could', 'credit', 'cya', 'day', 'do', 'doe', 'eat', 'favorit', 'genr', 'get', 'good', 'goodby', 'guy', 'hav', 'hello', 'help', 'hi', 'hour', 'how', 'i', 'id', 'interest', 'is', 'kind', 'lat', 'leav', 'lik', 'list', 'mastercard', 'menu', 'mop', 'most', 'mus', 'nam', 'of', 'old', 'on', 'op', 'reccommend', 'rent', 'see', 'shivam', 'should', 'someth', 'tak', 'thank', 'that', 'the', 'ther', 'thi', 'to', 'today', 'up', 'we', 'what', 'when', 'which', 'work', 'yo', 'you']\n"
     ]
    }
   ],
   "source": [
    "print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "WTJH-3wWKV9o"
   },
   "outputs": [],
   "source": [
    "labels = sorted(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "id": "cSrG_VBVKoT2",
    "outputId": "ffbea193-fa47-47b7-e323-0c379a6ea952"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'goodbye', 'greeting', 'hobbies', 'hours', 'mopeds', 'name', 'opentoday', 'payments', 'rental', 'shop', 'thanks', 'today']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "id": "ea-bC2fVfeIz",
    "outputId": "b065ec62-b16a-4c9d-a938-7fb484ea70ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Hi'], ['How', 'are', 'you'], ['Is', 'anyone', 'there', '?'], ['Hello'], ['Good', 'day'], ['Whats', 'up'], ['cya'], ['See', 'you', 'later'], ['Goodbye'], ['I', 'am', 'Leaving'], ['Have', 'a', 'Good', 'day'], ['how', 'old'], ['how', 'old', 'is', 'shivam'], ['what', 'is', 'your', 'age'], ['how', 'old', 'are', 'you'], ['age', '?'], ['what', 'is', 'your', 'name'], ['what', 'should', 'I', 'call', 'you'], ['whats', 'your', 'name', '?'], ['Id', 'like', 'to', 'buy', 'something'], ['whats', 'on', 'the', 'menu'], ['what', 'do', 'you', 'reccommend', '?'], ['could', 'i', 'get', 'something', 'to', 'eat'], ['when', 'are', 'you', 'guys', 'open'], ['what', 'are', 'your', 'hours'], ['hours', 'of', 'operation'], ['which', 'music', 'should', 'i', 'listen'], ['what', 'is', 'the', 'most', 'interesting', 'band'], ['what', 'is', 'favorite', 'genre', 'of', 'music'], ['Thanks'], ['Thank', 'you'], ['That', \"'s\", 'helpful'], ['Which', 'mopeds', 'do', 'you', 'have', '?'], ['What', 'kinds', 'of', 'mopeds', 'are', 'there', '?'], ['What', 'do', 'you', 'rent', '?'], ['Do', 'you', 'take', 'credit', 'cards', '?'], ['Do', 'you', 'accept', 'Mastercard', '?'], ['Are', 'you', 'cash', 'only', '?'], ['Are', 'you', 'open', 'today', '?'], ['When', 'do', 'you', 'open', 'today', '?'], ['What', 'are', 'your', 'hours', 'today', '?'], ['Can', 'we', 'rent', 'a', 'moped', '?'], ['I', \"'d\", 'like', 'to', 'rent', 'a', 'moped'], ['How', 'does', 'this', 'work', '?'], ['today']]\n"
     ]
    }
   ],
   "source": [
    "print(docs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ZAsaseduKqfO"
   },
   "outputs": [],
   "source": [
    "training = []\n",
    "output = []\n",
    "out_empty = [0 for _ in range(len(labels))]  #list of zeros corresponding to the tags\n",
    "for x,doc in enumerate(docs_x):\n",
    "  # print(x)\n",
    "  # print(doc)\n",
    "  bag = []   #bag of words to represent how many times the word appeared\n",
    "  wrds = [stemmer.stem(w) for w in doc] #stemming the words given\n",
    "  for w in words:\n",
    "    if w in wrds:\n",
    "      bag.append(1)  #appending 1 if words is present\n",
    "    else:\n",
    "      bag.append(0)   #otherwise zero\n",
    "    output_row = out_empty[:]  #appends the output row with zeros\n",
    "    output_row[labels.index(docs_y[x])]=1 #changes the output row if a word is present in docs_x\n",
    "    training.append(bag)\n",
    "    output.append(output_row)\n",
    "training = numpy.array(training)\n",
    "output = numpy.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "id": "FFJGbNNwQR1G",
    "outputId": "2961c16e-c646-4e76-fb13-c26529eaeb9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "id": "LbUlKViS6TUh",
    "outputId": "2ab9197e-5aad-4fb4-f0c3-ce3ca2e57a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "snIQVP9A6VCo"
   },
   "outputs": [],
   "source": [
    "tensorflow.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING THE deep learning MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "id": "l8P8MA1V-12C",
    "outputId": "bec83254-78f8-493a-a60f-0b1bcb60cd77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "net = tflearn.input_data(shape=[None,len(training[0])]) #for input data shaping the model with the size of inputs\n",
    "net = tflearn.fully_connected(net,8)  #hidden layer 1\n",
    "net = tflearn.fully_connected(net,8)  #hidden layer 2\n",
    "net = tflearn.fully_connected(net,len(output[0]),activation=\"softmax\")  #using softmax activation function\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net)#deep neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING THE MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "id": "pzNeLdv7B_T1",
    "outputId": "17d8dd5f-3ee2-43ce-cd68-d6c4a1f82a18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 416999  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 1.638s\n",
      "| Adam | epoch: 1000 | loss: 0.00000 - acc: 1.0000 -- iter: 3328/3330\n",
      "Training Step: 417000  | total loss: \u001b[1m\u001b[32m0.00000\u001b[0m\u001b[0m | time: 1.642s\n",
      "| Adam | epoch: 1000 | loss: 0.00000 - acc: 1.0000 -- iter: 3330/3330\n",
      "--\n",
      "INFO:tensorflow:/content/chatbot is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.fit(training,output,n_epoch=1000,batch_size=8,show_metric=True) #using epoch(no of times training the same model)\n",
    "model.save(\"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "_m8u7UmDCX_W"
   },
   "outputs": [],
   "source": [
    "def bag_of_words(s,words):\n",
    "  bag = [0 for _ in range(len(words))] #same process 0 for all the words in pattern\n",
    "  s_words = nltk.word_tokenize(s) #tokenize the words in the chat\n",
    "  s_words = [stemmer.stem(word.lower()) for word in s_words] #stemming the words\n",
    "\n",
    "  for se in s_words:\n",
    "    for i,w in enumerate(words):\n",
    "      if w==se:\n",
    "        bag[i]=1  #change the value of bag[i] from 0 to 1\n",
    "  return numpy.array(bag)#returning the value of bag of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pVZwGsUUMkAd"
   },
   "outputs": [],
   "source": [
    "def chat():\n",
    "  print(\"Let's start talking\")\n",
    "  while True:\n",
    "    inp = input(\"You:\")\n",
    "    if inp.lower()==\"quit\":\n",
    "      break\n",
    "    results = model.predict([bag_of_words(inp,words)]) #predicting the model but it shows the probability of tags\n",
    "    # print(results)\n",
    "    results_index = numpy.argmax(results) #finding the index of the tag with maximum probability\n",
    "    tag = labels[results_index] #now storing the the tag value in tag\n",
    "    # print(tag) \n",
    "    for tg in data[\"intents\"]:\n",
    "      if tg[\"tag\"]==tag:\n",
    "        responses = tg[\"responses\"] #finding the tag\n",
    "    print(random.choice(responses)) #given any random response from the patterns of the tag selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "p_8vBIP1Nhob",
    "outputId": "17870ef2-e3bf-4523-e6c4-e78f0fc8b983"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's start talking\n",
      "You:today\n",
      "For rentals today please call 1-800-MYMOPED\n",
      "You:what are my hobbies\n",
      "Hi there, how can I help?\n",
      "You:which music should i listen\n",
      "Ghoultown\n",
      "You:what is favorite band\n",
      "Pantera heavy metal\n",
      "You:do you accept credit card\n",
      "We accept VISA, Mastercard and AMEX\n",
      "You:i like something to eat\n",
      "Cookies are on the menu!\n",
      "You:how old is shivam\n",
      "21 years young!\n",
      "You:what is favorite genre of music\n",
      "Pantera heavy metal\n",
      "You:are you available today\n",
      "Same-day rentals please call 1-800-MYMOPED\n",
      "You:how many hours to work\n",
      "Cookies are on the menu!\n",
      "You:hours of operation\n",
      "We are open 7am-4pm Monday-Friday!\n",
      "You:goodbye\n",
      "Talk to you later\n",
      "You:quit\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "x4cspxitNizj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled11.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
